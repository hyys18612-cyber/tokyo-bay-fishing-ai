import tweepy
import os
import datetime
import pandas as pd
import joblib
import requests
import numpy as np
import warnings
from geopy.geocoders import Nominatim

warnings.filterwarnings('ignore')

# ==========================================
# 1. èªè¨¼æƒ…å ±ã®èª­ã¿è¾¼ã¿
# ==========================================
consumer_key = os.environ.get("TWITTER_API_KEY")
consumer_secret = os.environ.get("TWITTER_API_SECRET")
access_token = os.environ.get("TWITTER_ACCESS_TOKEN")
access_token_secret = os.environ.get("TWITTER_ACCESS_TOKEN_SECRET")

# ==========================================
# 2. è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
TARGET_AREAS = [
    ("æµ¦å®‰", "æµ¦å®‰ï¼ˆå¤¢ã®å³¶ãƒ»è‹¥æ´²ï¼‰"),
    ("å¤§é»’", "æ¨ªæµœï¼ˆã¿ãªã¨ã¿ã‚‰ã„ãƒ»å¤§é»’ï¼‰"),
    ("å¸‚åŸ", "åƒè‘‰ï¼ˆåƒè‘‰æ¸¯/å†…æˆ¿ï¼‰")
]

STATIONS = {
    "kawasaki": {"name": "å·å´äººå·¥å³¶", "lat": 35.49028, "lon": 139.83389, "file": "kawasaki_environment.xlsx"},
    "1goto": {"name": "1å·ç¯æ¨™", "lat": 35.53694, "lon": 139.95417, "file": "1goto_environment.xlsx"}
}

KNOWN_LOCATIONS = {
    "1å·ç¯æ¨™": (35.5369, 139.9542), "å·å´äººå·¥å³¶": (35.4903, 139.8339),
    "å·å´": (35.4903, 139.8339), "ç£¯å­": (35.4055, 139.6453),
    "æœ¬ç‰§": (35.4285, 139.6873), "å¤§é»’": (35.4487, 139.6945),
    "å¸‚åŸ": (35.5350, 140.0750), "æµ¦å®‰": (35.6400, 139.9417),
    "æ¤œè¦‹å·æ²–": (35.6108, 140.0233)
}
CANDIDATE_FACILITIES = ["æœ¬ç‰§", "å¤§é»’", "ç£¯å­", "å¸‚åŸ"]

MODELS_CONFIG = {
    "G1": {"model": "fish_catch_model_G1.pkl", "encoder": "label_encoders_G1.pkl"},
    "G2": {"model": "fish_catch_model_G2.pkl", "encoder": "label_encoders_G2.pkl"},
    "G3": {"model": "fish_catch_model_G3.pkl", "encoder": "label_encoders_G3.pkl"},
    "G4": {"model": "fish_catch_model_G4.pkl", "encoder": "label_encoders_G4.pkl"},
    "water": "sub/water_temp_model.pkl", "turbidity": "sub/turbidity_model.pkl",
    "salt": "sub/salt_model.pkl", "do": "sub/do_model.pkl"
}

# ==========================================
# 3. ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ç¾¤
# ==========================================
def get_short_reason(row_data, g_cpue_dict):
    """
    ãƒ„ã‚¤ãƒ¼ãƒˆç”¨ã«çŸ­ããƒ‘ãƒ³ãƒã®ã‚ã‚‹ç†ç”±ã‚’ç”Ÿæˆã™ã‚‹
    """
    wind = row_data['é¢¨é€Ÿ(m/s)']
    rain = row_data.get('é™æ°´é‡(mm)', 0)
    total_cpue = row_data['â˜…ç·é‡£æœ(CPUE)']
    
    # 1. ãƒã‚¬ãƒ†ã‚£ãƒ–è¦å› ï¼ˆæœ€å„ªå…ˆï¼‰
    if wind >= 8.0: return "âš ï¸å¼·é¢¨ï¼å®‰å…¨ç¬¬ä¸€ã§"
    if rain >= 5.0: return "â˜”é›¨å¤©æ³¨æ„"
    if total_cpue <= 1.5: return "ğŸ™ä¿®è¡Œã®äºˆæ„Ÿâ€¦"

    # 2. ãƒã‚¸ãƒ†ã‚£ãƒ–è¦å› ï¼ˆé­šç¨®åˆ¥ï¼‰
    # G1: ã‚¢ã‚¸ãƒ»ã‚¤ãƒ¯ã‚·ãƒ»ã‚µãƒ
    if g_cpue_dict.get('G1', 0) >= 8.0: return "ğŸŸã‚¢ã‚¸ãƒ»ã‚µãƒçˆ†é‡£!?"
    # G2: ã‚·ãƒ¼ãƒã‚¹ãƒ»ã‚¿ãƒã‚¦ã‚ª
    if g_cpue_dict.get('G2', 0) >= 0.5: return "ğŸ”¥ã‚·ãƒ¼ãƒã‚¹ç‹™ã„ç›®"
    # G3: ã‚«ãƒ¬ã‚¤ãƒ»ã‚­ã‚¹ãƒ»ã‚«ã‚µã‚´
    if g_cpue_dict.get('G3', 0) >= 1.5: return "ğŸ£åº•ç‰©ãŒç†±ã„ï¼"
    
    # 3. ãã®ä»–
    if total_cpue >= 10.0: return "âœ¨å…¨ä½“çš„ã«é«˜æ´»æ€§"
    
    return "ğŸ§ãƒ¯ãƒ³ãƒãƒ£ãƒ³ã‚ã‚‹ã‹ã‚‚"

def evaluate_cpue_rank(val):
    if val >= 20.0: return "S"
    if val >= 10.0: return "A"
    if val >= 4.0: return "B"
    if val >= 1.2: return "C"
    return "D"

# --- ä»¥ä¸‹ã€å…±é€šãƒ­ã‚¸ãƒƒã‚¯ (çœç•¥ãªã—) ---
def match_features(model, available_data):
    try:
        if hasattr(model, 'feature_name_'): required_cols = model.feature_name_
        elif hasattr(model, 'feature_name'): required_cols = model.feature_name()
        else: required_cols = []
    except: required_cols = []
    
    if len(required_cols) == 0: return pd.DataFrame([available_data])
    input_data = {}
    for col in required_cols:
        val = available_data.get(col)
        if val is None:
            for k, v in available_data.items():
                if k in col or col in k: val = v; break
        input_data[col] = [val if val is not None else 0]
    return pd.DataFrame(input_data)

def get_coordinates(place_name):
    for key, val in KNOWN_LOCATIONS.items():
        if key in str(place_name): return val
    try:
        geolocator = Nominatim(user_agent="fishing_predictor_bot")
        loc = geolocator.geocode(place_name)
        if loc: return (loc.latitude, loc.longitude)
    except: pass
    return None

def calculate_moon_age(dt):
    base = datetime.datetime(2000, 1, 6, 12, 0)
    diff = dt - base
    return round((diff.total_seconds() / 86400) % 29.53058867, 1)

def get_weather_code_label(code):
    if code <= 1: return "æ™´ã‚Œ"
    if code <= 48: return "æ›‡ã‚Š"
    return "é›¨"

def fetch_weather_forecast_range(lat, lon, start_dt, end_dt):
    fetch_start = start_dt - datetime.timedelta(days=5)
    url = "https://api.open-meteo.com/v1/forecast"
    params = {
        "latitude": lat, "longitude": lon, 
        "start_date": fetch_start.strftime("%Y-%m-%d"),
        "end_date": end_dt.strftime("%Y-%m-%d"), 
        "daily": "temperature_2m_mean,wind_speed_10m_max,precipitation_sum,pressure_msl_mean,weather_code",
        "timezone": "Asia/Tokyo", "wind_speed_unit": "ms"
    }
    try:
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        if "daily" in data: return pd.DataFrame(data["daily"])
    except: return None
    return None

def find_best_substitute(target_weather_row, date_str, candidates_weather_cache):
    best_facility = "æœ¬ç‰§"
    min_score = float('inf')
    t_wind = target_weather_row.get('wind_speed_10m_max', 0)
    t_temp = target_weather_row.get('temperature_2m_mean', 15)
    for facility in CANDIDATE_FACILITIES:
        df_cand = candidates_weather_cache.get(facility)
        if df_cand is None: continue
        cand_row = df_cand[df_cand['time'] == pd.to_datetime(date_str)]
        if len(cand_row) == 0: continue
        cand_row = cand_row.iloc[0]
        diff = abs(t_wind - cand_row['wind_speed_10m_max']) * 2.0 + abs(t_temp - cand_row['temperature_2m_mean'])
        if diff < min_score: min_score = diff; best_facility = facility
    return best_facility

def get_latest_marine_data(target_lat, target_lon):
    def calc_dist(lat1, lon1, lat2, lon2): return np.sqrt((lat1 - lat2)**2 + (lon1 - lon2)**2)
    dk = calc_dist(target_lat, target_lon, STATIONS["kawasaki"]["lat"], STATIONS["kawasaki"]["lon"])
    d1 = calc_dist(target_lat, target_lon, STATIONS["1goto"]["lat"], STATIONS["1goto"]["lon"])
    st = STATIONS["kawasaki"] if dk < d1 else STATIONS["1goto"]
    
    if not os.path.exists(st['file']):
        return None, None
    try:
        df = pd.read_excel(st['file'])
        lr = df.iloc[-1]
        vals = {"water_temp": lr['æ°´æ¸©(ä¸Šå±¤)(â„ƒ)'], "turbidity": lr['æ¿åº¦(ä¸Šå±¤)(NTU)'], "do": lr['DO(ä¸Šå±¤)(mg/L)'], "salt": lr['å¡©åˆ†(ä¸Šå±¤)(-)']}
        return vals, pd.to_datetime(lr.iloc[0])
    except: return None, None

def safe_encode(encoder, val):
    try: return encoder.transform([val])[0]
    except: return 0 

# ==========================================
# 4. ãƒ¡ã‚¤ãƒ³å‡¦ç† (ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ -> ãƒ„ã‚¤ãƒ¼ãƒˆ)
# ==========================================
try:
    print("ğŸ“‚ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
    models = {}; encoders = {}; 
    for key, path in MODELS_CONFIG.items():
        if isinstance(path, dict):
            if os.path.exists(path["model"]):
                models[key] = joblib.load(path["model"])
                encoders[key] = joblib.load(path["encoder"])
        else:
            if os.path.exists(path): models[key] = joblib.load(path)

    tomorrow = datetime.date.today() + datetime.timedelta(days=1)
    TARGET_DATE_STR = tomorrow.strftime("%Y-%m-%d")
    
    # æ›œæ—¥ã®æ—¥æœ¬èªè¡¨è¨˜
    weekdays = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
    weekday_str = weekdays[tomorrow.weekday()]
    
    forecast_results = []
    
    for place_name, display_name in TARGET_AREAS:
        coords = get_coordinates(place_name)
        if not coords: continue

        current, last_marine_date = get_latest_marine_data(coords[0], coords[1])
        if current is None:
            current = {"water_temp": 12.0, "turbidity": 2.5, "salt": 31.5, "do": 9.5}
            last_marine_date = datetime.datetime.now() - datetime.timedelta(days=1)

        target_start_dt = pd.to_datetime(TARGET_DATE_STR)
        sim_start_dt = last_marine_date + datetime.timedelta(days=1)
        if target_start_dt < sim_start_dt: target_start_dt = sim_start_dt

        df_w = fetch_weather_forecast_range(coords[0], coords[1], sim_start_dt, target_start_dt)
        if df_w is None: continue
        
        c_cache = {}
        for f in CANDIDATE_FACILITIES:
            cc = get_coordinates(f)
            if cc:
                d = fetch_weather_forecast_range(cc[0], cc[1], sim_start_dt, target_start_dt)
                if d is not None: d['time'] = pd.to_datetime(d['time']); c_cache[f] = d

        df_w['time'] = pd.to_datetime(df_w['time'])
        target_row = df_w[df_w['time'].dt.strftime('%Y-%m-%d') == TARGET_DATE_STR]
        
        if not target_row.empty:
            row = target_row.iloc[0]
            date = row['time']
            w_label = get_weather_code_label(row['weather_code'])
            
            pool = {
                'æ°—æ¸©': row['temperature_2m_mean'], 'é¢¨é€Ÿ': row.get('wind_speed_10m_max', 0),
                'é™æ°´é‡': row.get('precipitation_sum', 0), 'æ°—åœ§': row.get('pressure_msl_mean', 1013),
                'æ—¥ä»˜': date.dayofyear, 'æ—¥ä»˜(365)': date.dayofyear, 'æœˆé½¢': calculate_moon_age(date),
                'å‰æ—¥ã®æ°´æ¸©': current['water_temp'], 'æ°´æ¸©': current['water_temp'],
                'å‰æ—¥ã®æ¿åº¦': current['turbidity'], 'æ¿åº¦': current['turbidity'],
                'å‰æ—¥ã®å¡©åˆ†': current['salt'], 'å¡©åˆ†': current['salt'], 'å‰æ—¥ã®DO': current['do'], 'DO': current['do'],
                'å¹³å‡æ°—æ¸©': row['temperature_2m_mean'], '5æ—¥å¹³å‡æ°—æ¸©': row['temperature_2m_mean']
            }
            try:
                pw = models['water'].predict(match_features(models['water'], pool))[0] if 'water' in models else current['water_temp']
                pt = models['turbidity'].predict(match_features(models['turbidity'], pool))[0] if 'turbidity' in models else current['turbidity']
                ps = models['salt'].predict(match_features(models['salt'], pool))[0] if 'salt' in models else current['salt']
                pd_val = models['do'].predict(match_features(models['do'], pool))[0] if 'do' in models else current['do']
                pt = max(0.1, pt)
                pool.update({'äºˆæ¸¬æ°´æ¸©': pw, 'æ°´æ¸©': pw, 'å‰æ—¥ã¨ã®æ°´æ¸©å·®': pw - current['water_temp'], 'æ¿åº¦': pt, 'å¡©åˆ†': ps, 'DO': pd_val})
            except: pw, pt, ps, pd_val = current.values()

            sub_place = find_best_substitute(row, TARGET_DATE_STR, c_cache)
            g1_total = 0
            g_cpue_sums = {}
            total_all_cpue = 0
            
            for g_name in ["G1", "G2", "G3", "G4"]:
                if g_name in models:
                    m, e = models[g_name], encoders[g_name]
                    pool['æ–½è¨­å'] = safe_encode(e['æ–½è¨­å'], sub_place)
                    pool['å¤©æ°—'] = safe_encode(e['å¤©æ°—'], w_label)
                    g_sum = 0
                    for fish in e['é­šç¨®'].classes_:
                        pool['é­šç¨®'] = safe_encode(e['é­šç¨®'], fish)
                        pred = max(0, m.predict(match_features(m, pool))[0])
                        g_sum += pred
                    g_cpue_sums[g_name] = g_sum
                    total_all_cpue += g_sum
            
            # çµæœæ ¼ç´
            rank = evaluate_cpue_rank(total_all_cpue)
            reason = get_short_reason({
                'é¢¨é€Ÿ(m/s)': row.get('wind_speed_10m_max', 0),
                'é™æ°´é‡(mm)': row.get('precipitation_sum', 0),
                'â˜…ç·é‡£æœ(CPUE)': total_all_cpue
            }, g_cpue_sums)
            
            # çŸ­ã„å ´æ‰€åã‚’ä½œã‚‹ (æµ¦å®‰ï¼ˆå¤¢ã®å³¶...ï¼‰ -> æµ¦å®‰)
            short_name = place_name 
            
            forecast_results.append({
                "name": short_name,
                "full_name": display_name,
                "rank": rank,
                "reason": reason,
                "cpue": total_all_cpue
            })

    # --- ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡ç”Ÿæˆ ---
    if forecast_results:
        # CPUEãŒé«˜ã„é †ã«ä¸¦ã³æ›¿ãˆ
        forecast_results.sort(key=lambda x: x['cpue'], reverse=True)
        best_spot = forecast_results[0]
        
        # æœ¬æ–‡çµ„ã¿ç«‹ã¦
        tweet_text = f"ã€é‡£è¡Œåˆ¤æ–­AIï½œæ±äº¬æ¹¾ã€‘\n\n"
        tweet_text += f"æ˜æ—¥ï¼ˆ{tomorrow.strftime('%m/%d')}ãƒ»{weekday_str}ï¼‰\n"
        tweet_text += f"é‡£ã‚Šã«è¡Œãã‹è¿·ã£ã¦ã‚‹äººã¸\n\n"
        
        for res in forecast_results:
            # ãƒ©ãƒ³ã‚¯ã®çµµæ–‡å­—
            rank_emoji = {'S':'ğŸ”¥', 'A':'â—', 'B':'ã€‡', 'C':'â–³', 'D':'â˜”'}.get(res['rank'], 'ãƒ»')
            tweet_text += f"ğŸ“{res['name']}\n"
            tweet_text += f"â†’ {res['rank']} ({res['reason']})\n\n"
        
        # ç· ã‚ã®è¨€è‘‰
        tweet_text += f"æ˜æ—¥ã¯{best_spot['name']}ãŒãŠã™ã™ã‚ï¼ğŸŸ\n"
        tweet_text += f"ğŸ‘‡è©³ç´°äºˆå ±\n"
        tweet_text += f"https://tokyo-bay-fishing-ai-ypd33onggtcjxnh69ryijz.streamlit.app/"

        print("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ„ã‚¤ãƒ¼ãƒˆ:")
        print(tweet_text)

        # v2ã§ãƒ„ã‚¤ãƒ¼ãƒˆ
        client = tweepy.Client(
            consumer_key=consumer_key, consumer_secret=consumer_secret,
            access_token=access_token, access_token_secret=access_token_secret
        )
        client.create_tweet(text=tweet_text)
        print("âœ… ãƒ„ã‚¤ãƒ¼ãƒˆæˆåŠŸï¼")
        
    else:
        print("âŒ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    raise e
