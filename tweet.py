import tweepy
import os
import datetime
import pandas as pd
import joblib
import requests
import numpy as np
from geopy.geocoders import Nominatim
import warnings
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.font_manager as fm

warnings.filterwarnings('ignore')

# ==========================================
# 1. èªè¨¼æƒ…å ±ã®èª­ã¿è¾¼ã¿
# ==========================================
consumer_key = os.environ.get("TWITTER_API_KEY")
consumer_secret = os.environ.get("TWITTER_API_SECRET")
access_token = os.environ.get("TWITTER_ACCESS_TOKEN")
access_token_secret = os.environ.get("TWITTER_ACCESS_TOKEN_SECRET")

# ==========================================
# 2. è¨­å®šã‚¨ãƒªã‚¢ (Final_predict_card_Full.pyã‚ˆã‚Š)
# ==========================================
TARGET_AREAS = [
    ("æµ¦å®‰", "æµ¦å®‰ï¼ˆå¤¢ã®å³¶ãƒ»è‹¥æ´²ï¼‰"),
    ("å¤§é»’", "æ¨ªæµœï¼ˆã¿ãªã¨ã¿ã‚‰ã„ãƒ»å¤§é»’ï¼‰"),
    ("å¸‚åŸ", "åƒè‘‰ï¼ˆåƒè‘‰æ¸¯/å†…æˆ¿ï¼‰")
]

STATIONS = {
    "kawasaki": {"name": "å·å´äººå·¥å³¶", "lat": 35.49028, "lon": 139.83389, "file": "kawasaki_environment.xlsx"},
    "1goto": {"name": "1å·ç¯æ¨™", "lat": 35.53694, "lon": 139.95417, "file": "1goto_environment.xlsx"}
}

KNOWN_LOCATIONS = {
    "1å·ç¯æ¨™": (35.5369, 139.9542), "å·å´äººå·¥å³¶": (35.4903, 139.8339),
    "å·å´": (35.4903, 139.8339), "ç£¯å­": (35.4055, 139.6453),
    "æœ¬ç‰§": (35.4285, 139.6873), "å¤§é»’": (35.4487, 139.6945),
    "å¸‚åŸ": (35.5350, 140.0750), "æµ¦å®‰": (35.6400, 139.9417),
    "æ¤œè¦‹å·æ²–": (35.6108, 140.0233)
}
CANDIDATE_FACILITIES = ["æœ¬ç‰§", "å¤§é»’", "ç£¯å­", "å¸‚åŸ"]

# GitHubã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆã«åˆã‚ã›ã¦ãƒ‘ã‚¹ã‚’èª¿æ•´ï¼ˆå¿…è¦ãªã‚‰å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰
MODELS_CONFIG = {
    "G1": {"model": "fish_catch_model_G1.pkl", "encoder": "label_encoders_G1.pkl"},
    "G2": {"model": "fish_catch_model_G2.pkl", "encoder": "label_encoders_G2.pkl"},
    "G3": {"model": "fish_catch_model_G3.pkl", "encoder": "label_encoders_G3.pkl"},
    "G4": {"model": "fish_catch_model_G4.pkl", "encoder": "label_encoders_G4.pkl"},
    "water": "sub/water_temp_model.pkl", "turbidity": "sub/turbidity_model.pkl",
    "salt": "sub/salt_model.pkl", "do": "sub/do_model.pkl"
}

# ==========================================
# 3. ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ç¾¤
# ==========================================
def get_angler_comment(row_data, g_cpue_dict):
    wind = row_data['é¢¨é€Ÿ(m/s)']
    rain = row_data.get('é™æ°´é‡(mm)', 0)
    temp_diff = row_data.get('å‰æ—¥æ°´æ¸©å·®', 0)
    total_cpue = row_data['â˜…ç·é‡£æœ(CPUE)']
    
    if wind >= 8.0: return "âš  å¼·é¢¨äºˆå ±ï¼å®‰å…¨ç¬¬ä¸€ã§æ’¤é€€ã‚‚å‹‡æ°—"
    if rain >= 5.0: return "â˜” æœ¬é™ã‚Šäºˆå ±ã€‚é›¨å…·å¿…é ˆã€è¶³å…ƒæ³¨æ„"
    if total_cpue >= 20.0: return "â˜…çˆ†é‡£è­¦å ±ï¼ã‚¯ãƒ¼ãƒ©ãƒ¼æº€ã‚¿ãƒ³ã®æº–å‚™ã‚’"
    if g_cpue_dict.get('G2', 0) >= 0.5: return "å¤§ç‰©ãƒãƒ£ãƒ³ã‚¹ï¼ãƒ«ã‚¢ãƒ¼ãƒ»æ³³ãŒã›ã§æ”»ã‚ã‚"
    if g_cpue_dict.get('G1', 0) >= 8.0: return "â— ã‚¢ã‚¸ãƒ»ã‚¤ãƒ¯ã‚·å›éŠï¼ã‚µãƒ“ã‚­ã§æ‰‹å …ã"
    if g_cpue_dict.get('G3', 0) >= 1.5: return "åº•ç‰©ãŒç†±ã„ï¼æŠ•ã’é‡£ã‚Šã§ã˜ã£ãã‚Šæ¢ã‚Œ"
    if temp_diff <= -0.5: return "æ°´æ¸©ä½ä¸‹ä¸­ã€‚æ´»æ€§ä½ã„ãªã‚‰æ·±å ´ãƒ»ãƒœãƒˆãƒ ã¸"
    if temp_diff >= 0.5: return "æ°´æ¸©ä¸Šæ˜‡ï¼æµ…å ´ã®é«˜æ´»æ€§ãªå€‹ä½“ã‚’ç‹™ãˆ"
    if total_cpue >= 10.0: return "å¥½æ¡ä»¶ï¼è‰²ã€…ãªé­šç¨®ãŒç‹™ãˆã‚‹ä¸€æ—¥"
    if total_cpue <= 3.0: return "æˆ‘æ…¢ã®å±•é–‹ã€‚æ½®ã®å¤‰ã‚ã‚Šç›®ã«é›†ä¸­ã—ã‚ˆã†"
    return "ã‚¨ãƒ³ã‚¸ãƒ§ã‚¤ãƒ•ã‚£ãƒƒã‚·ãƒ³ã‚°ï¼ä¸€ç™ºé€†è»¢ã‚’ç‹™ãˆ"

def evaluate_cpue_total_scaled(val):
    if val >= 20.0: return "S (çˆ†é‡£)"
    if val >= 10.0: return "A (å¥½èª¿)"
    if val >= 4.0: return "B (æ™®é€š)"
    if val >= 1.2: return "C (æ¸‹ã„)"
    return "D (æ¿€æ¸‹)"

def evaluate_cpue_single(val):
    if val >= 3.0: return "S (çˆ†é‡£)"
    if val >= 1.0: return "A (å¥½èª¿)"
    if val >= 0.3: return "B (æ™®é€š)"
    if val >= 0.1: return "C (æ¸‹ã„)"
    return "D (æ¿€æ¸‹)"

def get_model_features(model):
    try:
        if hasattr(model, 'feature_name_'): return model.feature_name_
        elif hasattr(model, 'feature_name'): return model.feature_name()
    except: pass
    return []

def match_features(model, available_data):
    required_cols = get_model_features(model)
    if len(required_cols) == 0: return pd.DataFrame([available_data])
    input_data = {}
    for col in required_cols:
        val = available_data.get(col)
        if val is None:
            for k, v in available_data.items():
                if k in col or col in k: val = v; break
        input_data[col] = [val if val is not None else 0]
    return pd.DataFrame(input_data)

def get_coordinates(place_name):
    for key, val in KNOWN_LOCATIONS.items():
        if key in str(place_name): return val
    try:
        geolocator = Nominatim(user_agent="fishing_predictor_bot")
        loc = geolocator.geocode(place_name)
        if loc: return (loc.latitude, loc.longitude)
    except: pass
    return None

def calculate_moon_age(dt):
    base = datetime.datetime(2000, 1, 6, 12, 0)
    diff = dt - base
    return round((diff.total_seconds() / 86400) % 29.53058867, 1)

def get_weather_code_label(code):
    if code <= 1: return "æ™´ã‚Œ"
    if code <= 48: return "æ›‡ã‚Š"
    return "é›¨"

def fetch_weather_forecast_range(lat, lon, start_dt, end_dt):
    fetch_start = start_dt - datetime.timedelta(days=5)
    url = "https://api.open-meteo.com/v1/forecast"
    params = {
        "latitude": lat, "longitude": lon, 
        "start_date": fetch_start.strftime("%Y-%m-%d"),
        "end_date": end_dt.strftime("%Y-%m-%d"), 
        "daily": "temperature_2m_mean,wind_speed_10m_max,precipitation_sum,pressure_msl_mean,weather_code",
        "timezone": "Asia/Tokyo", "wind_speed_unit": "ms"
    }
    try:
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        if "daily" in data: return pd.DataFrame(data["daily"])
    except: return None
    return None

def find_best_substitute(target_weather_row, date_str, candidates_weather_cache):
    best_facility = "æœ¬ç‰§"
    min_score = float('inf')
    t_wind = target_weather_row.get('wind_speed_10m_max', 0)
    t_temp = target_weather_row.get('temperature_2m_mean', 15)
    for facility in CANDIDATE_FACILITIES:
        df_cand = candidates_weather_cache.get(facility)
        if df_cand is None: continue
        cand_row = df_cand[df_cand['time'] == pd.to_datetime(date_str)]
        if len(cand_row) == 0: continue
        cand_row = cand_row.iloc[0]
        diff = abs(t_wind - cand_row['wind_speed_10m_max']) * 2.0 + abs(t_temp - cand_row['temperature_2m_mean'])
        if diff < min_score: min_score = diff; best_facility = facility
    return best_facility

def get_latest_marine_data(target_lat, target_lon):
    def calc_dist(lat1, lon1, lat2, lon2): return np.sqrt((lat1 - lat2)**2 + (lon1 - lon2)**2)
    dk = calc_dist(target_lat, target_lon, STATIONS["kawasaki"]["lat"], STATIONS["kawasaki"]["lon"])
    d1 = calc_dist(target_lat, target_lon, STATIONS["1goto"]["lat"], STATIONS["1goto"]["lon"])
    st = STATIONS["kawasaki"] if dk < d1 else STATIONS["1goto"]
    
    if not os.path.exists(st['file']):
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
        print(f"âš ï¸ Marine data file not found: {st['file']}")
        return None, None
    try:
        df = pd.read_excel(st['file'])
        lr = df.iloc[-1]
        vals = {"water_temp": lr['æ°´æ¸©(ä¸Šå±¤)(â„ƒ)'], "turbidity": lr['æ¿åº¦(ä¸Šå±¤)(NTU)'], "do": lr['DO(ä¸Šå±¤)(mg/L)'], "salt": lr['å¡©åˆ†(ä¸Šå±¤)(-)']}
        return vals, pd.to_datetime(lr.iloc[0])
    except: return None, None

def safe_encode(encoder, val):
    try: return encoder.transform([val])[0]
    except: return 0 

# --- ç”»åƒç”Ÿæˆé–¢æ•° (ipaexg.ttfå¯¾å¿œç‰ˆ) ---
def generate_fishing_card(card_data_list, target_date_str):
    print("\nğŸ¨ äºˆå ±ã‚«ãƒ¼ãƒ‰ç”»åƒã‚’ç”Ÿæˆä¸­...")
    
    # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š (ipaexg.ttfã‚’å„ªå…ˆ)
    font_path = "ipaexg.ttf"
    if os.path.exists(font_path):
        fm.fontManager.addfont(font_path)
        plt.rcParams['font.family'] = 'IPAexGothic'
    else:
        plt.rcParams['font.family'] = 'sans-serif'
            
    fig, ax = plt.subplots(figsize=(10, 6.5))
    fig.patch.set_facecolor('#f0f8ff')
    ax.set_facecolor('#f0f8ff')
    ax.axis('off')

    dt = datetime.datetime.strptime(target_date_str, "%Y-%m-%d")
    date_display = dt.strftime("%Y/%m/%d (%a)")
    
    plt.text(0.5, 0.93, 'æ±äº¬æ¹¾ é‡£æœäºˆæ¸¬AI', ha='center', va='center', fontsize=22, fontweight='bold', color='#003366')
    plt.text(0.5, 0.85, f'Target Date: {date_display}', ha='center', va='center', fontsize=13, color='#444444')

    y_positions = [0.65, 0.40, 0.15]
    colors = {'A (å¥½èª¿)': '#ffcccc', 'B (æ™®é€š)': '#fff5cc', 'C (æ¸‹ã„)': '#e6f2ff', 'D (æ¿€æ¸‹)': '#f0f0f0', 'S (çˆ†é‡£)': '#ff9999'}
    text_colors = {'A (å¥½èª¿)': '#cc0000', 'B (æ™®é€š)': '#996600', 'C (æ¸‹ã„)': '#003399', 'D (æ¿€æ¸‹)': '#666666', 'S (çˆ†é‡£)': '#cc0000'}

    for i, item in enumerate(card_data_list):
        if i >= 3: break
        y = y_positions[i]
        area_label = item['area_label']
        row_data = item['data']
        comment = item['ai_comment']
        
        rect = patches.FancyBboxPatch((0.05, y - 0.1), 0.9, 0.2, boxstyle="round,pad=0.02", linewidth=1, edgecolor='#cccccc', facecolor='white')
        ax.add_patch(rect)
        
        plt.text(0.1, y + 0.03, area_label, fontsize=16, fontweight='bold', color='#333333', va='center')
        
        judge = row_data['ç·åˆåˆ¤å®š']
        bg_c = colors.get(judge, '#ffffff')
        txt_c = text_colors.get(judge, '#000000')
        
        v_rect = patches.FancyBboxPatch((0.55, y - 0.08), 0.35, 0.16, boxstyle="round,pad=0.02", linewidth=0, facecolor=bg_c)
        ax.add_patch(v_rect)
        
        judge_short = judge.split(' ')[0]
        judge_jp = judge.split(' ')[1].replace('(', '').replace(')', '')
        plt.text(0.725, y + 0.03, f"{judge_short} {judge_jp}", ha='center', va='center', fontsize=20, fontweight='bold', color=txt_c)

        details = f"å¤©æ°—: {row_data['å¤©æ°—']} | é¢¨: {row_data['é¢¨é€Ÿ(m/s)']}m | æ°´æ¸©: {row_data['æ°´æ¸©(â„ƒ)']}â„ƒ | ç·åˆCPUE: {row_data['â˜…ç·é‡£æœ(CPUE)']}"
        plt.text(0.1, y - 0.05, details, fontsize=11, color='#555555', va='center')

        plt.text(0.725, y - 0.04, comment, ha='center', va='center', fontsize=11, fontweight='bold', color='#d9534f')

    plt.text(0.5, 0.02, 'Powered by Python & Fishing Forecast Model', ha='center', va='center', fontsize=10, color='#888888')
    plt.tight_layout()
    filename = 'fishing_forecast_card.png'
    plt.savefig(filename, dpi=150) # Twitterç”¨ã«å°‘ã—è»½ãã™ã‚‹
    plt.close()
    return filename

# ==========================================
# 4. ãƒ¡ã‚¤ãƒ³å‡¦ç† (äºˆæ¸¬ -> ç”»åƒç”Ÿæˆ -> ãƒ„ã‚¤ãƒ¼ãƒˆ)
# ==========================================
try:
    print("ğŸ“‚ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
    models = {}; encoders = {}; 
    for key, path in MODELS_CONFIG.items():
        if isinstance(path, dict):
            if os.path.exists(path["model"]):
                models[key] = joblib.load(path["model"])
                encoders[key] = joblib.load(path["encoder"])
            else: print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãªã—: {path['model']}")
        else:
            if os.path.exists(path): models[key] = joblib.load(path)

    # æ—¥ä»˜è¨­å®š (æ˜æ—¥)
    tomorrow = datetime.date.today() + datetime.timedelta(days=1)
    TARGET_DATE_STR = tomorrow.strftime("%Y-%m-%d")
    
    card_data_list = []
    
    for place_name, display_name in TARGET_AREAS:
        print(f"\nğŸš€ {place_name} ã®äºˆæ¸¬é–‹å§‹...")
        coords = get_coordinates(place_name)
        if not coords: continue

        current, last_marine_date = get_latest_marine_data(coords[0], coords[1])
        if current is None:
            # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ (1æœˆæƒ³å®š)
            current = {"water_temp": 12.0, "turbidity": 2.5, "salt": 31.5, "do": 9.5}
            last_marine_date = datetime.datetime.now() - datetime.timedelta(days=1)

        target_start_dt = pd.to_datetime(TARGET_DATE_STR)
        sim_start_dt = last_marine_date + datetime.timedelta(days=1)
        if target_start_dt < sim_start_dt: target_start_dt = sim_start_dt

        df_w = fetch_weather_forecast_range(coords[0], coords[1], sim_start_dt, target_start_dt)
        if df_w is None: continue
        
        c_cache = {}
        for f in CANDIDATE_FACILITIES:
            cc = get_coordinates(f)
            if cc:
                d = fetch_weather_forecast_range(cc[0], cc[1], sim_start_dt, target_start_dt)
                if d is not None: d['time'] = pd.to_datetime(d['time']); c_cache[f] = d

        df_w['time'] = pd.to_datetime(df_w['time'])
        df_w['5æ—¥å¹³å‡æ°—æ¸©'] = df_w['temperature_2m_mean'].rolling(window=5).mean()
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ—¥ä»˜ã®è¡Œã‚’æ¢ã™
        target_row = df_w[df_w['time'].dt.strftime('%Y-%m-%d') == TARGET_DATE_STR]
        
        if not target_row.empty:
            row = target_row.iloc[0]
            date = row['time']
            d_str = TARGET_DATE_STR
            w_label = get_weather_code_label(row['weather_code'])
            
            # ç‰¹å¾´é‡ãƒ—ãƒ¼ãƒ«ä½œæˆ
            pool = {
                'æ°—æ¸©': row['temperature_2m_mean'], 'é¢¨é€Ÿ': row.get('wind_speed_10m_max', 0),
                'é™æ°´é‡': row.get('precipitation_sum', 0), 'æ°—åœ§': row.get('pressure_msl_mean', 1013),
                'æ—¥ä»˜': date.dayofyear, 'æ—¥ä»˜(365)': date.dayofyear, 'æœˆé½¢': calculate_moon_age(date),
                'å‰æ—¥ã®æ°´æ¸©': current['water_temp'], 'æ°´æ¸©': current['water_temp'],
                'å‰æ—¥ã®æ¿åº¦': current['turbidity'], 'æ¿åº¦': current['turbidity'],
                'å‰æ—¥ã®å¡©åˆ†': current['salt'], 'å¡©åˆ†': current['salt'], 'å‰æ—¥ã®DO': current['do'], 'DO': current['do'],
                'å¹³å‡æ°—æ¸©': row['temperature_2m_mean'], '5æ—¥å¹³å‡æ°—æ¸©': row['temperature_2m_mean']
            }
            
            # ç’°å¢ƒäºˆæ¸¬ (æ°´æ¸©ãªã©)
            try:
                pw = models['water'].predict(match_features(models['water'], pool))[0] if 'water' in models else current['water_temp']
                pt = models['turbidity'].predict(match_features(models['turbidity'], pool))[0] if 'turbidity' in models else current['turbidity']
                ps = models['salt'].predict(match_features(models['salt'], pool))[0] if 'salt' in models else current['salt']
                pd_val = models['do'].predict(match_features(models['do'], pool))[0] if 'do' in models else current['do']
                pt = max(0.1, pt)
                pool.update({'äºˆæ¸¬æ°´æ¸©': pw, 'æ°´æ¸©': pw, 'å‰æ—¥ã¨ã®æ°´æ¸©å·®': pw - current['water_temp'], 'æ¿åº¦': pt, 'å¡©åˆ†': ps, 'DO': pd_val})
            except: pw, pt, ps, pd_val = current.values()

            # é‡£æœäºˆæ¸¬
            sub_place = find_best_substitute(row, d_str, c_cache)
            g1_total = 0
            fish_preds = {}
            g_cpue_sums = {}
            total_all_cpue = 0
            
            for g_name in ["G1", "G2", "G3", "G4"]:
                if g_name in models:
                    m, e = models[g_name], encoders[g_name]
                    pool['æ–½è¨­å'] = safe_encode(e['æ–½è¨­å'], sub_place)
                    pool['å¤©æ°—'] = safe_encode(e['å¤©æ°—'], w_label)
                    g_sum = 0
                    for fish in e['é­šç¨®'].classes_:
                        pool['é­šç¨®'] = safe_encode(e['é­šç¨®'], fish)
                        pred = max(0, m.predict(match_features(m, pool))[0])
                        fish_preds[fish] = pred
                        g_sum += pred
                    g_cpue_sums[g_name] = g_sum
                    total_all_cpue += g_sum
            
            grade = evaluate_cpue_total_scaled(total_all_cpue)
            
            # ãƒ‡ãƒ¼ã‚¿æ ¼ç´
            result_row = {
                "æ—¥ä»˜": d_str, "å¤©æ°—": w_label, 
                "é¢¨é€Ÿ(m/s)": round(row.get('wind_speed_10m_max', 0), 1),
                "æ°´æ¸©(â„ƒ)": round(pw, 1), 
                "å‰æ—¥æ°´æ¸©å·®": round(pw - current['water_temp'], 1),
                "ç·åˆåˆ¤å®š": grade, 
                "â˜…ç·é‡£æœ(CPUE)": round(total_all_cpue, 1)
            }
            comment = get_angler_comment(result_row, g_cpue_sums)
            
            card_data_list.append({
                "area_label": display_name, 
                "data": result_row,
                "ai_comment": comment
            })

    # ç”»åƒç”Ÿæˆ
    if card_data_list:
        image_file = generate_fishing_card(card_data_list, TARGET_DATE_STR)
        
        # --- TwitteræŠ•ç¨¿ ---
        print("ğŸ“¤ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        # v1.1 èªè¨¼
        auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)
        api = tweepy.API(auth)
        # v2 èªè¨¼
        client = tweepy.Client(consumer_key=consumer_key, consumer_secret=consumer_secret, access_token=access_token, access_token_secret=access_token_secret)
        
        media = api.media_upload(filename=image_file)
        
        tweet_text = f"""ğŸ“Š æ±äº¬æ¹¾é‡£æœäºˆæ¸¬ ({tomorrow.strftime('%m/%d')})

ã€é‡£è¡Œåˆ¤æ–­AIäºˆå ±ã€‘
æ˜æ—¥ã€æ±äº¬æ¹¾ã§é‡£ã‚Šã«è¡Œãã‹è¿·ã‚ã‚Œã¦ã„ã‚‹æ–¹ã¯å‚è€ƒã«ã—ã¦ãã ã•ã„ï¼
ç”»åƒã§è©³ç´°ã‚’ãƒã‚§ãƒƒã‚¯ğŸ‘‡

Webç‰ˆã§ã¯ã‚ˆã‚Šè©³ç´°ãªåˆ†æãŒè¦‹ã‚Œã¾ã™ğŸŸ
https://tokyo-bay-fishing-ai-ypd33onggtcjxnh69ryijz.streamlit.app/

#é‡£ã‚Š #æ±äº¬æ¹¾ #ã‚·ãƒ¼ãƒã‚¹ #ã‚¢ã‚¸ãƒ³ã‚° #é‡£ã‚ŠAI
"""
        client.create_tweet(text=tweet_text, media_ids=[media.media_id])
        print("âœ… ã‚«ãƒ¼ãƒ‰ç”»åƒä»˜ããƒ„ã‚¤ãƒ¼ãƒˆæˆåŠŸï¼")
    else:
        print("âŒ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


